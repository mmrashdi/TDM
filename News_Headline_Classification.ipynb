{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDLHLWdyaYZh"
   },
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qY7J6ll_RCJR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"uci-news-aggregator.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ikLxNisuRcN_",
    "outputId": "b8377951-660f-489f-d587-8a34ac8d290a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STORY</th>\n",
       "      <th>HOSTNAME</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.latimes.com</td>\n",
       "      <td>1394470370698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.livemint.com</td>\n",
       "      <td>1394470371207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n",
       "      <td>Moneynews</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.moneynews.com</td>\n",
       "      <td>1394470372027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1  Fed official says weak data caused by weather,...   \n",
       "1   2  Fed's Charles Plosser sees high bar for change...   \n",
       "2   3  US open: Stocks fall after Fed official hints ...   \n",
       "3   4  Fed risks falling 'behind the curve', Charles ...   \n",
       "4   5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
       "\n",
       "                                                 URL          PUBLISHER  \\\n",
       "0  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
       "1  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
       "2  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
       "3  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
       "4  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
       "\n",
       "  CATEGORY                          STORY             HOSTNAME      TIMESTAMP  \n",
       "0        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n",
       "1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n",
       "2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n",
       "3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n",
       "4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted column and keep only title and category columns\n",
    "df = df[['TITLE','CATEGORY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE CATEGORY\n",
       "0  Fed official says weak data caused by weather,...        b\n",
       "1  Fed's Charles Plosser sees high bar for change...        b\n",
       "2  US open: Stocks fall after Fed official hints ...        b\n",
       "3  Fed risks falling 'behind the curve', Charles ...        b\n",
       "4  Fed's Plosser: Nasty Weather Has Curbed Job Gr...        b"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YUkit7BzcFTw"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\"\"\"\n",
    "since our target labels in text , we need to convert it to numeric values for that \n",
    "we can use sklearn label encoder <<<  class1,class2,class3 --> 1,2,3 >>\n",
    "\"\"\"\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['CATEGORY'] =  label_encoder.fit_transform( df['CATEGORY'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QXdBK_-Nc4PU"
   },
   "outputs": [],
   "source": [
    "class_labels = label_encoder.classes_\n",
    "\n",
    "# devide the dataset into train and test sets\n",
    "# extract feature array and target labels into two place holders\n",
    "X , Y =  df['TITLE'] , df['CATEGORY'].values\n",
    "#splitting the data into 80 and 20 split\n",
    "train_X, test_X, y_train, y_test = train_test_split( X , Y ,  test_size=0.2, \n",
    "                                                    random_state=42, shuffle=True , stratify = Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlVEjcu7d6rp",
    "outputId": "c15c4082-ec50-45fb-857d-1c9312141b04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (422419, 2)\n",
      "TRAIN Dataset: 337935\n",
      "TEST Dataset: 84484\n"
     ]
    }
   ],
   "source": [
    "# train test dataset stats\n",
    "print(\"FULL Dataset: {}\".format( df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(len(train_X)))\n",
    "print(\"TEST Dataset: {}\".format(len(test_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogV1bMOzagY4"
   },
   "source": [
    "# 1. Model Traning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVdNx0d4aSKh"
   },
   "source": [
    "## a) normalize text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3J_5GvLYoEp"
   },
   "source": [
    "> remove english stop words from sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QxUIbJxmYEKx"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "define set of english stopwords , which will not be contain any valueable information for any text analysis task\n",
    "in case we need to remove them\n",
    "\"\"\"\n",
    "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're','s', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "\n",
    "STOPWORDS = set(stopwordlist)\n",
    "\n",
    "# function to remove stop words\n",
    "def cleaning_stopwords(text):\n",
    "    \"\"\"\n",
    "    first split the sentence into words after that check if word inside the stopword list above , if so remove that word\n",
    "    \"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHN2XtoCZKmx"
   },
   "source": [
    "> remove punctuations from sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HzeYarsuSPlI"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "# get most frequent punctuations from english language\n",
    "english_punctuations = string.punctuation\n",
    "\n",
    "# function to remove punctuations\n",
    "def cleaning_punctuations(text):\n",
    "    chars_clean = []\n",
    "    for char in text :\n",
    "      # iterate over every character and check if that belongs to punctuation , is so remove that\n",
    "      if char not in english_punctuations  :\n",
    "        chars_clean.append( char )\n",
    "    # join the chars and restate the sentence\n",
    "    text_nopunct = \"\".join( chars_clean ) \n",
    "    return text_nopunct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAmJImS8Z3iY"
   },
   "source": [
    "> stemming the words using nltk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7o6zu6SITo_K"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# initialize the poter stemmer \n",
    "st = nltk.PorterStemmer()\n",
    "def stemming_on_text(data):\n",
    "    # split the sentence into words and then apply stemmer to stem words into it's base \n",
    "    text = [st.stem(word) for word in data.split() ]\n",
    "    return \" \".join( text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "up_TIRGOaFXZ"
   },
   "source": [
    "> clean numbers from senetnce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9FWn4tLeSaKZ"
   },
   "outputs": [],
   "source": [
    "# function to remove numbers\n",
    "def cleaning_numbers(data):\n",
    "    # replace the number with blank\n",
    "    return re.sub('[0-9]+', '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fvRvoj4oaI8I"
   },
   "outputs": [],
   "source": [
    "def normalize_data( df ):\n",
    "  \"\"\"\n",
    "  using apply method with pandas dataframe we can apply above functions to each column value inside \n",
    "  dataframe\n",
    "  \"\"\"\n",
    "  # remove stop wrods\n",
    "  df= df.apply(lambda text: cleaning_stopwords(text))\n",
    "\n",
    "  # remove numbers\n",
    "  df= df.apply(lambda x: cleaning_numbers(x))\n",
    "\n",
    "  # apply stemmer\n",
    "  df = df.apply(lambda x: stemming_on_text(x))\n",
    "\n",
    "  # remove punchuation\n",
    "  df= df.apply(lambda x: cleaning_punctuations(x) )\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "b0y4AUANa3gg"
   },
   "outputs": [],
   "source": [
    "# apply dataset normalization\n",
    "df_normalized_train = normalize_data( train_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3OH3ohObJrw",
    "outputId": "0edfc98d-fcec-4e2e-ff97-e6cf3b050482"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311397    appl supplier start make inch inch iphon next ...\n",
       "277764    astronaut reid wiseman take twitter share life...\n",
       "68461     possibl to use offic for ipad without offic su...\n",
       "333723    the dow inch higher strength from disney micro...\n",
       "385527    ​i think marvel is ly to everybodi about the n...\n",
       "Name: TITLE, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train dataset after normalize\n",
    "df_normalized_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFNFro8zb7UK"
   },
   "source": [
    "## b) Extract features and build feature set and feature vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "IKYePinobg8g"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3j9diffeQlb"
   },
   "source": [
    "> define the feature vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "hmt-vq_Xd4pa"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "define the sklearn pipeline \n",
    "\n",
    "step 1. user counter vectorizer to vectorize each sentence based on vocabulary\n",
    "step 2. use TFIDF feature extraction method (https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.YmL99nZByUk)\n",
    "\"\"\"\n",
    "# define the complete pipeline\n",
    "feature_extractor = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_6UbYB1WfbsJ"
   },
   "outputs": [],
   "source": [
    "# extract features from train dataset , apply the above sklearn pipeline\n",
    "\n",
    "X_features = feature_extractor.fit_transform( df_normalized_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmqtB8IwhD_K"
   },
   "source": [
    "## c) Use supervised learning algorithm Naïve Bayes & Logistic Regression to build a predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETgTYJF2nWzS"
   },
   "source": [
    "> Naive Bayes Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dp6sae7Yfs34",
    "outputId": "2002c64b-0f4c-4f07-bda5-f8cde949d1e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9287022652285203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.90      0.92      0.91     92774\n",
      "           e       0.95      0.97      0.96    121975\n",
      "           m       0.97      0.86      0.91     36511\n",
      "           t       0.91      0.91      0.91     86675\n",
      "\n",
      "    accuracy                           0.93    337935\n",
      "   macro avg       0.93      0.91      0.92    337935\n",
      "weighted avg       0.93      0.93      0.93    337935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 1. naive bayers classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# train the model using extracted features and target label set\n",
    "nb_classifier.fit( X_features , y_train )\n",
    "\n",
    "# model performance evaluation on train set\n",
    "y_train_pred_nb = nb_classifier.predict( X_features )\n",
    "\n",
    "# analyze the results\n",
    "print('accuracy %s' % accuracy_score( y_train_pred_nb , y_train ))\n",
    "# print the classification report on train dataset performance\n",
    "print(classification_report( y_train , y_train_pred_nb  ,target_names = list(class_labels)  , zero_division = 0  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4192SdTcnboU"
   },
   "source": [
    "> Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "io9bmN0Qnfmq",
    "outputId": "5d31fc99-dc12-4bd3-f600-24df8aa5c15b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9534259546954296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.93      0.94      0.94     92774\n",
      "           e       0.97      0.98      0.98    121975\n",
      "           m       0.97      0.93      0.95     36511\n",
      "           t       0.94      0.94      0.94     86675\n",
      "\n",
      "    accuracy                           0.95    337935\n",
      "   macro avg       0.95      0.95      0.95    337935\n",
      "weighted avg       0.95      0.95      0.95    337935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 2. logistic regression classifier\n",
    "LR_classifier = LogisticRegression( solver = 'lbfgs' , max_iter = 500  )\n",
    "\n",
    "# train the model using extracted features and target label set\n",
    "LR_classifier.fit( X_features , y_train )\n",
    "\n",
    "# model performance evaluation on train set\n",
    "y_train_pred_lr = LR_classifier.predict( X_features )\n",
    "\n",
    "# analyze the results\n",
    "print('accuracy %s' % accuracy_score( y_train_pred_lr , y_train ))\n",
    "print(classification_report( y_train , y_train_pred_lr  ,target_names = list(class_labels)  , zero_division = 0  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RZhs111jBD8"
   },
   "source": [
    "# 2. Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDLP5KQXljP7"
   },
   "source": [
    "## a) Normalize testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6fktWSCIjDrx"
   },
   "outputs": [],
   "source": [
    "# apply normalization on test dataset\n",
    "df_normalized_test = normalize_data( test_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hbB9qPIlwwi",
    "outputId": "0de5a11e-7d47-4030-d794-47358cb0754a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139452    astronom have found first earthsized habit zon...\n",
       "196479                            video barclay cut job new\n",
       "91525     us juri hit takeda eli lilli whop us billion p...\n",
       "228371                     ciara  futur have a new babi boy\n",
       "79276                      fruit veggi aplenti optim health\n",
       "Name: TITLE, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample visualization on test dataset after normalize\n",
    "df_normalized_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3xRndbUl0Px"
   },
   "source": [
    "## b) Extract features using training feature vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "D0K8SnfVl925"
   },
   "outputs": [],
   "source": [
    "# extract features from test dataset\n",
    "\n",
    "X_features_test = feature_extractor.transform( df_normalized_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRvARFxDmEJ_"
   },
   "source": [
    "## c) Predict the news article class using training model naive bayes and logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "YuGdewT7ijth"
   },
   "outputs": [],
   "source": [
    "# take predictions from trained model naive bayes classifier\n",
    "y_test_pred_nb = nb_classifier.predict( X_features_test )\n",
    "\n",
    "# take predictions from trained model logistic regression\n",
    "y_test_pred_lr = LR_classifier.predict( X_features_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVsG3qp8nBMR"
   },
   "source": [
    "## d) Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zR4dJO0cqIAL"
   },
   "source": [
    "> performance analysis on naive bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gSp5Vhf0m69J",
    "outputId": "3f1194f8-a0c8-47ed-a257-6fa381b404f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model Performance Analysis\n",
      "\n",
      "accuracy 0.9208844278206524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.89      0.91      0.90     23193\n",
      "           e       0.94      0.97      0.96     30494\n",
      "           m       0.97      0.84      0.90      9128\n",
      "           t       0.90      0.90      0.90     21669\n",
      "\n",
      "    accuracy                           0.92     84484\n",
      "   macro avg       0.93      0.90      0.91     84484\n",
      "weighted avg       0.92      0.92      0.92     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# analyze the results\n",
    "print(\"Naive Bayes Model Performance Analysis\\n\")\n",
    "print('accuracy %s' % accuracy_score( y_test_pred_nb , y_test ))\n",
    "print(classification_report( y_test , y_test_pred_nb  ,target_names = list(class_labels)  , zero_division = 0  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dBjm5bmqfFs"
   },
   "source": [
    "> performance analysis on logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t5HutZgunJPQ",
    "outputId": "41effd01-00a7-411e-fd2e-306656c75523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Performance Analysis\n",
      "\n",
      "accuracy 0.9407935230339473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.92      0.92      0.92     23193\n",
      "           e       0.96      0.98      0.97     30494\n",
      "           m       0.96      0.91      0.93      9128\n",
      "           t       0.93      0.92      0.92     21669\n",
      "\n",
      "    accuracy                           0.94     84484\n",
      "   macro avg       0.94      0.93      0.94     84484\n",
      "weighted avg       0.94      0.94      0.94     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# analyze the results\n",
    "print(\"Logistic Regression Model Performance Analysis\\n\")\n",
    "print('accuracy %s' % accuracy_score( y_test_pred_lr , y_test ))\n",
    "print(classification_report( y_test , y_test_pred_lr  ,target_names = list(class_labels)  , zero_division = 0  ))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "News_Headline_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
